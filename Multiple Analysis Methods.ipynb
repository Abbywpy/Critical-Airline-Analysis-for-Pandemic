{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce3fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8832a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = nx.read_gml(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f5583",
   "metadata": {},
   "source": [
    "### Degree Centrality Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dba5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a pseudo graph\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([(1, 2), (1, 3), (1, 4), (2, 3), (3, 4), (4, 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e17a3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most influential node is: 1\n",
      "The top 3 influential nodes are:  1 3 4\n"
     ]
    }
   ],
   "source": [
    "# Compute the degree centrality for each node\n",
    "deg_cent = nx.degree_centrality(G)\n",
    "\n",
    "# Sort the nodes by their degree centrality\n",
    "sorted_deg_cent = sorted(deg_cent, key=deg_cent.get, reverse=True)\n",
    "\n",
    "# Print the most influential node--the highest degree centrality\n",
    "print(\"The most influential node is:\", sorted_deg_cent[0])\n",
    "\n",
    "#Print Top 3\n",
    "print(\"The top 3 influential nodes are: \",sorted_deg_cent[0],sorted_deg_cent[1],sorted_deg_cent[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0c7d0",
   "metadata": {},
   "source": [
    "### Betweenness Centrality Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428757a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most influential node is: 4\n",
      "The top 3 influential nodes are:  4 1 3\n"
     ]
    }
   ],
   "source": [
    "# Calculate betweenness centrality for each node\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "# Sort the nodes by their beweenness centrality\n",
    "sorted_betweenness_centrality = sorted(betweenness_centrality, key=betweenness_centrality.get, reverse=True)\n",
    "\n",
    "# Print the most influential node--the highest betweenness centrality\n",
    "print(\"The most influential node is:\", sorted_betweenness_centrality[0])\n",
    "\n",
    "#Print Top 3\n",
    "print(\"The top 3 influential nodes are: \",sorted_betweenness_centrality[0],sorted_betweenness_centrality[1],sorted_betweenness_centrality[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135fc5f4",
   "metadata": {},
   "source": [
    "### Closeness Centrality Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "707305f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most influential node is: 1\n",
      "The top 3 influential nodes are:  1 3 4\n"
     ]
    }
   ],
   "source": [
    "# Calculate closeness centrality for each node\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "# Sort the nodes by their closeness centrality\n",
    "sorted_closeness_centrality = sorted(closeness_centrality, key=closeness_centrality.get, reverse=True)\n",
    "\n",
    "# Print the most influential node--the highest closeness centrality\n",
    "print(\"The most influential node is:\", sorted_closeness_centrality[0])\n",
    "\n",
    "#Print Top 3\n",
    "print(\"The top 3 influential nodes are: \",sorted_closeness_centrality[0],sorted_closeness_centrality[1],sorted_closeness_centrality[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2274428f",
   "metadata": {},
   "source": [
    "### Eigenvector Centrality Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e46c72a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most influential node is: 1\n",
      "The top 3 influential nodes are:  1 3 4\n"
     ]
    }
   ],
   "source": [
    "# Calculate eigenvector centrality for each node\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G)\n",
    "\n",
    "# Sort the nodes by their eigenvector centrality\n",
    "sorted_eigenvector_centrality = sorted(eigenvector_centrality, key=eigenvector_centrality.get, reverse=True)\n",
    "\n",
    "# Print the most influential node--the highest eigenvector centrality\n",
    "print(\"The most influential node is:\", sorted_eigenvector_centrality[0])\n",
    "\n",
    "#Print Top 3\n",
    "print(\"The top 3 influential nodes are: \",sorted_eigenvector_centrality[0],sorted_eigenvector_centrality[1],sorted_eigenvector_centrality[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724db809",
   "metadata": {},
   "source": [
    "### PageRank Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e5ac82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most influential node is: 4\n",
      "The top 3 influential nodes are:  4 1 3\n"
     ]
    }
   ],
   "source": [
    "# Calculate PageRank for each node\n",
    "pagerank = nx.pagerank(G)\n",
    "\n",
    "# Sort the nodes by their pagerank\n",
    "sorted_pagerank = sorted(pagerank, key=pagerank.get, reverse=True)\n",
    "\n",
    "# Print the most influential node--the highest pagerank\n",
    "print(\"The most influential node is:\", sorted_pagerank[0])\n",
    "\n",
    "#Print Top 3\n",
    "print(\"The top 3 influential nodes are: \",sorted_pagerank[0],sorted_pagerank[1],sorted_pagerank[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7673f",
   "metadata": {},
   "source": [
    "### HITs Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "59669774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most influential node is: 3\n",
      "The top 3 influential nodes are:  3 2 4\n"
     ]
    }
   ],
   "source": [
    "# Calculate HITS for each node\n",
    "hits = nx.hits(G)\n",
    "\n",
    "\n",
    "# Sort the nodes by their HITS score\n",
    "a_hits = dict(hits[0])\n",
    "sorted_hits = sorted(a_hits, key=a_hits.get, reverse = True)\n",
    "\n",
    "# Print the most influential node--the highest HITS score\n",
    "print(\"The most influential node is:\", sorted_hits[0])\n",
    "\n",
    "#Print Top 3\n",
    "print(\"The top 3 influential nodes are: \",sorted_hits[0],sorted_hits[1],sorted_hits[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5dd8ddb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: 0.1593346781975113,\n",
       "  2: 0.2136144776199625,\n",
       "  3: 0.2541016883650524,\n",
       "  4: 0.21361447761996244,\n",
       "  5: 0.15933467819751132},\n",
       " {1: 0.15933467819751135,\n",
       "  2: 0.21361447761996247,\n",
       "  3: 0.25410168836505237,\n",
       "  4: 0.2136144776199625,\n",
       "  5: 0.1593346781975113})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55c061d",
   "metadata": {},
   "source": [
    "### Global and Local Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5491c91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Global influence\n",
    "\n",
    "neighbors = []\n",
    "A = 1.1\n",
    "# num_nodes\n",
    "N = 0\n",
    "glbinflu = {}\n",
    "count_neighbors={}\n",
    "for i in G.nodes():\n",
    "    N += 1\n",
    "for node1 in G.nodes():\n",
    "    for node2 in G.nodes():\n",
    "        if node1 != node2:\n",
    "            # Use the common_neighbors method to find the common neighbors\n",
    "            common_neighbors = nx.common_neighbors(G, node1, node2)\n",
    "            for neighbor in common_neighbors:\n",
    "                neighbors.append(neighbor)\n",
    "            #Count the occurences of common neighbors\n",
    "            count_neighbors = Counter(neighbors)\n",
    "        # Calculate global influence\n",
    "        n2 = int(node2)\n",
    "        degree2 = G.degree[n2]\n",
    "        sum_pow = 0\n",
    "        #count_neighbors = dict(count_neighbors)\n",
    "        for v in count_neighbors.values():\n",
    "            sum_pow += pow(A, v)\n",
    "        glbinflu_2 = degree2 * sum_pow\n",
    "        glbinflu[n2] = glbinflu_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "494900e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 4, 3, 4, 3, 1, 1, 3, 2, 4, 1, 1, 4, 3, 1, 3, 1, 4, 4]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d671018e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 16.498806920200007,\n",
       " 2: 25.96556311833001,\n",
       " 3: 35.26495482444002,\n",
       " 4: 27.304651130163016,\n",
       " 5: 18.203100753442012}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glbinflu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c257e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the local influence\n",
    "\n",
    "#Compute the sum of degree in the Graph\n",
    "nodes = [i for i in G.nodes()]\n",
    "degrees = [G.degree(i) for i in nodes]\n",
    "sum_degree = 0\n",
    "for i in degrees:\n",
    "    sum_degree += i\n",
    "\n",
    "locinflu = {}\n",
    "for node3 in G.nodes():\n",
    "    # Get a list of the nearest neighbors\n",
    "    Nei = nx.neighbors(G,node3)\n",
    "    n3 = int(node3)\n",
    "    degree3 = G.degree[n3]\n",
    "    for m in Nei:\n",
    "        degree_m = G.degree(i)\n",
    "        # Calculate the Degree Centrality\n",
    "        DC_m = degree_m/(N-1)\n",
    "        degree_m = G.degree[m]\n",
    "        # Calculate the average degree\n",
    "        averD_m = (sum_degree - degree_m)/degree_m\n",
    "        # Calculate contribution probability\n",
    "        p_m = 1/averD_m\n",
    "        # Calculate local influence\n",
    "        locinflu_n = 0\n",
    "        pre_loc = DC_m * p_m\n",
    "        locinflu_n += pre_loc \n",
    "        locinflu[n3] = locinflu_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "418c048b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.30000000000000004,\n",
       " 2: 0.20454545454545459,\n",
       " 3: 0.125,\n",
       " 4: 0.125,\n",
       " 5: 0.20454545454545459}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locinflu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02c853f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Influ = {}\n",
    "\n",
    "# Iterate over the keys in glb\n",
    "for key in glbinflu:\n",
    "  # Get the values from dict1 and loc\n",
    "  value1 = glbinflu[key]\n",
    "  value2 = locinflu[key]\n",
    "  \n",
    "  # Multiply the values and store the result in the new dictionary\n",
    "  Influ[key] = value1 * value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b81deb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_Influ = sorted(Influ, key=Influ.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6cb972e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 3, 5, 4]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_Influ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee7af0f",
   "metadata": {},
   "source": [
    "### H-index Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654dd7d9",
   "metadata": {},
   "source": [
    "一篇文章中提到的一种方法，以下为最简单的示例代码，还未应用到我们的network里\n",
    "\n",
    "原理如下：\n",
    "If at most n edges with a weight of not less than n are connected to a node, then its H-index is n. The H-index method can be applied to a weighted network. To some extent, the H-index can be regarded as a compromise between the strength of the node and the degree of centrality. However, this method has a huge drawback, that is, the value of the edge weight needs to be in the appropriate range, otherwise the effective rankings cannot be obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5166ce55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The H-index is 4.\n"
     ]
    }
   ],
   "source": [
    "# List of publications and the number of citations each has received\n",
    "publications = [\n",
    "    (\"paper1\", 10),\n",
    "    (\"paper2\", 8),\n",
    "    (\"paper3\", 5),\n",
    "    (\"paper4\", 4),\n",
    "    (\"paper5\", 3),\n",
    "    (\"paper6\", 2),\n",
    "    (\"paper7\", 1)\n",
    "]\n",
    "\n",
    "# Sort the publications in descending order by the number of citations\n",
    "sorted_publications = sorted(publications, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Find the largest number h such that at least h publications have h or more citations\n",
    "h_index = 0\n",
    "for i, (paper, citations) in enumerate(sorted_publications):\n",
    "    if citations >= i + 1:\n",
    "        h_index = i + 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Print the H-index\n",
    "print(f\"The H-index is {h_index}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc1c89",
   "metadata": {},
   "source": [
    "### K-Shell Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213cb90e",
   "metadata": {},
   "source": [
    "Nodes are assigned to k shells according to their remaining degree, which is obtained by successive pruning of nodes with degree\n",
    "smaller than the kS value of the current layer. We start by removing all nodes with degree k=1. After removing all the nodes with k=1, some nodes may be left with one link, so we continue pruning the system iteratively until there is no node left with k=1 in the network. The removed nodes, along with the corresponding links, form a k shell with index k_S=1. In a similar fashion, we iteratively remove the next k shell, k_S=2, and continue removing higher-k shells until all nodes are removed. As a result, each node is associated with one k_S index, and the network can be viewed as the union of all k shells. The resulting classification of a node can be very different than when the degree k is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "33fbca46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x1e4535cf130>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_shells = nx.k_shell(G, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5028e97c",
   "metadata": {},
   "source": [
    "what do we get from the result?\n",
    "\n",
    "how to determine the suitable value of k?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadd629f",
   "metadata": {},
   "source": [
    "### K-truss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5903059",
   "metadata": {},
   "source": [
    "obtain a k-truss subgraph from a given graph:\n",
    "\n",
    "1.Begin with the original graph G and initialize a k-truss subgraph T to be empty.\n",
    "\n",
    "2.Iterate over all the edges in G, and for each edge e, count the number of triangles it is a part of. If the number of triangles is less than k-1, remove the edge from G and do not add it to T.\n",
    "\n",
    "3.Repeat step 2 until all the edges in G have been processed.\n",
    "\n",
    "4.The resulting graph T is the k-truss subgraph of G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b1155ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_triangles(G, i, j):\n",
    "    # Initialize the triangle count to 0\n",
    "    triangles = 0\n",
    "\n",
    "    # Iterate over all the vertices in G\n",
    "    for v in range(N):\n",
    "        # If the vertices (i, v) and (j, v) are both edges in G, increment the triangle count\n",
    "        if G.has_edge(i, v) and G.has_edge(j, v):\n",
    "            triangles += 1\n",
    "\n",
    "    return triangles\n",
    "\n",
    "def k_truss(G, k):\n",
    "    # Initialize the k-truss subgraph T to be empty\n",
    "    T = []\n",
    "\n",
    "    # Iterate over all the edges in G\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            if G.has_edge(i, j):\n",
    "                # Count the number of triangles the edge (i, j) is a part of\n",
    "                triangles = count_triangles(G, i, j)\n",
    "\n",
    "                # If the edge (i, j) is part of at least k-1 triangles, add it to T\n",
    "                if triangles >= k-1:\n",
    "                    T.append((i, j))\n",
    "\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5149073d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 3)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_truss(G,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e860a22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
